import os
import sys
import asyncio
import mimetypes
import logging
import time
import traceback
import tempfile
from datetime import datetime, timedelta, timezone
import httpx
from telethon import TelegramClient
from telethon.sessions import StringSession
from supabase import create_client

# æ—¥å¿—é…ç½®ä¼˜åŒ–
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    stream=sys.stdout 
)
logger = logging.getLogger(__name__)

# ä¼˜å…ˆåŠ è½½æŠ¥è­¦é…ç½®
N8N_WEBHOOK_URL = os.environ.get('N8N_WEBHOOK_URL')
N8N_AUTH_TOKEN = os.environ.get('N8N_AUTH_TOKEN')

# æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
async def send_alert(message, level="Critical"):
    """
    é€šç”¨æŠ¥è­¦å‘é€å‡½æ•° - å‘é€è‡³ n8nï¼Œç”± n8n è·¯ç”±è‡³ Global Error Handler
    """
    logger.error(f"ğŸš¨ Sending Alert to n8n: {message}")
    if not N8N_WEBHOOK_URL:
        logger.error("âŒ Cannot send alert: N8N_WEBHOOK_URL is missing.")
        return

    try:
        async with httpx.AsyncClient() as http_client:
            await http_client.post(
                N8N_WEBHOOK_URL,
                json={
                    "brand": "System_Alert",
                    "content": f"ğŸš¨ Pythonè„šæœ¬æŠ¥è­¦ [{level}]: {message}",
                    "message_id": "error_alert",
                    "date": datetime.now().isoformat()
                },
                headers={'Authorization': N8N_AUTH_TOKEN} if N8N_AUTH_TOKEN else {},
                timeout=15 
            )
        logger.info("âœ… Error alert sent to n8n.")
    except Exception as e:
        logger.error(f"âš ï¸ Failed to send error alert: {e}")

def upload_to_supabase_with_retry(supabase_client, bucket_name, file_path, folder_name, max_retries=3):
    """
    Supabase ä¸Šä¼ å‡½æ•° (åŒæ­¥ç‰ˆ)
    è¿è¡Œåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹å¿ƒè·³
    """
    file_name = os.path.basename(file_path)
    # ç®€å•çš„æ–‡ä»¶åé˜²æ­¢è¦†ç›–
    remote_path = f"{folder_name}/{int(datetime.now().timestamp())}_{file_name}"
    mime_type = mimetypes.guess_type(file_path)[0] or "application/octet-stream"
    
    for attempt in range(max_retries):
        try:
            with open(file_path, 'rb') as f:
                supabase_client.storage.from_(bucket_name).upload(
                    path=remote_path,
                    file=f,
                    file_options={"content-type": mime_type}
                )
            public_url = supabase_client.storage.from_(bucket_name).get_public_url(remote_path)
            # è¿”å› URL å’Œ Path (ç”¨äºå›æ»š)
            return public_url, remote_path
            
        except Exception as e:
            logger.warning(f"âš ï¸ Upload attempt {attempt+1}/{max_retries} failed: {e}")
            time.sleep(2) 
    
    logger.error(f"âŒ Failed to upload {file_name} after {max_retries} attempts")
    return None, None

def delete_from_supabase(supabase_client, bucket_name, paths):
    """æ‰¹é‡åˆ é™¤ Supabase æ–‡ä»¶ (ç”¨äºå›æ»š)"""
    if not paths: return
    try:
        supabase_client.storage.from_(bucket_name).remove(paths)
        logger.info(f"ğŸ§¹ Rolled back (deleted) {len(paths)} orphaned files.")
    except Exception as e:
        logger.error(f"âš ï¸ Failed to clean up orphaned files: {e}")

async def main_logic():
    """ä¸»é€»è¾‘å°è£…"""
    start_time = time.time()
    
    # åŠ è½½ç¯å¢ƒå˜é‡ (Fail Fast)
    try:
        api_id = int(os.environ['TG_API_ID'])
        api_hash = os.environ['TG_API_HASH']
        session_string = os.environ['TG_SESSION_STRING']
        supabase_url = os.environ['SUPABASE_URL']
        supabase_key = os.environ['SUPABASE_KEY']
        target_channels_env = os.environ['TARGET_CHANNELS']
    except KeyError as e:
        error_msg = f"Missing environment variable: {e}"
        await send_alert(error_msg, level="Config_Error")
        raise ValueError(error_msg)

    # è§£æé¢‘é“æ˜ å°„
    raw_targets = target_channels_env.split(',')
    channel_map = {}
    for item in raw_targets:
        if ':' in item:
            parts = item.strip().split(':')
            if len(parts) == 2:
                key = parts[0].strip()
                val = parts[1].strip()
                channel_map[key] = val if val else "Uncategorized"
        elif item.strip():
            channel_map[item.strip()] = "Uncategorized"

    logger.info("ğŸš€ Daily Service Script Started...")
    logger.info(f"ğŸ“‚ Brand Mapping: {channel_map}") 

    # åˆå§‹åŒ– Telegram Client
    client = TelegramClient(
        StringSession(session_string), 
        api_id, 
        api_hash,
        connection_retries=5, 
        auto_reconnect=True,
        request_retries=3,
        device_model="N8N_Worker_Server", 
        system_version="Linux_Railway_Env",
        app_version="2.0.0"
    )
    
    supabase = create_client(supabase_url, supabase_key)
    BUCKET_NAME = "daily_post_assets"

    # è¿æ¥ Telegram
    try:
        logger.info("ğŸ“¡ Connecting to Telegram...")
        await client.connect()
        if not await client.is_user_authorized():
            await send_alert("âŒ Session Invalid/Expired. Please update TG_SESSION_STRING.", level="Fatal")
            os._exit(1)
        logger.info("âœ… Connected & Authorized.")
    except Exception as e:
        await send_alert(f"ğŸ”¥ Connection Failed: {str(e)}", level="Fatal")
        raise e 

    # é…ç½®åŠ è½½ (æ—¶é—´çª—å£)
    manila_tz = timezone(timedelta(hours=8))
    now_manila = datetime.now(manila_tz)
    
    try:
        fetch_hours = int(os.environ.get('FETCH_HOURS', 26))
    except ValueError:
        fetch_hours = 26

    try:
        fetch_limit = int(os.environ.get('FETCH_LIMIT', 200))
    except ValueError:
        fetch_limit = 200

    cutoff_time = now_manila - timedelta(hours=fetch_hours)
    logger.info(f"âš™ï¸ Config: Lookback={fetch_hours}h (Cutoff: {cutoff_time}), Limit={fetch_limit}")

    processed_groups = set()
    payloads = []

    # ä¸´æ—¶ç›®å½•ç®¡ç†
    with tempfile.TemporaryDirectory() as temp_dir:
        
        # éå†é¢‘é“
        for channel, brand_folder in channel_map.items():
            logger.info(f"ğŸ” Checking channel: {channel} --> {brand_folder}")
            
            # æŸ¥é‡é€»è¾‘ (æ‰¹é‡é¢„åŠ è½½)
            existing_ids_set = set()
            try:
                db_check_limit = max(fetch_limit * 2, 1000)
                
                existing_data = supabase.table('daily_post_archive') \
                    .select('message_id') \
                    .eq('brand', brand_folder) \
                    .eq('source_channel', channel) \
                    .order('inserted_at', desc=True) \
                    .limit(db_check_limit) \
                    .execute()
                
                existing_ids_set = {row['message_id'] for row in existing_data.data}
                logger.info(f"ğŸ“š Loaded {len(existing_ids_set)} existing IDs for cache.")
            except Exception as e:
                logger.error(f"âš ï¸ Batch Check Error: {e}")
                # ç»§ç»­æ‰§è¡Œï¼Œä¾é åç»­é€»è¾‘

            try:
                # æŠ“å–æ¶ˆæ¯
                async for message in client.iter_messages(channel, offset_date=cutoff_time, reverse=True, limit=fetch_limit):
                    
                    if message.action: continue 
                    if not message.text and not message.media: continue
                    
                    # å†…å­˜æŸ¥é‡
                    if str(message.id) in existing_ids_set:
                        continue

                    # æ•°æ®å‡†å¤‡
                    media_urls = []
                    media_type = "text"
                    final_text = message.text or ""
                    final_msg_id = str(message.id)
                    is_payload_valid = True 

                    # åˆ†æ”¯ A: åª’ä½“ç»„ (Album)
                    if message.grouped_id:
                        if message.grouped_id in processed_groups: continue 
                        processed_groups.add(message.grouped_id)
                        media_type = "album"
                        
                        group_msgs = await client.get_messages(channel, ids=list(range(message.id, message.id + 9)))
                        real_group = [m for m in group_msgs if m and m.grouped_id == message.grouped_id]
                        if not real_group: real_group = [message]

                        # è®°å½•æœ¬æ¬¡ç›¸å†Œä¸Šä¼ çš„æ‰€æœ‰ pathï¼Œç”¨äºå›æ»š
                        album_uploaded_paths = []

                        for m in real_group:
                            if m.media:
                                path = None
                                try:
                                    path = await m.download_media(file=temp_dir)
                                    if path:
                                        # ä¸Šä¼ 
                                        url, remote_path = await asyncio.to_thread(
                                            upload_to_supabase_with_retry, 
                                            supabase, BUCKET_NAME, path, brand_folder
                                        )

                                        if url: 
                                            media_urls.append(url)
                                            album_uploaded_paths.append(remote_path)
                                        else:
                                            # ä¸Šä¼ å¤±è´¥ -> è§¦å‘å›æ»š
                                            error_msg = f"Supabase Upload Failed mid-album (Msg ID: {message.id})"
                                            logger.error(error_msg)
                                            await send_alert(error_msg, level="Upload_Error")
                                            is_payload_valid = False
                                            
                                            # æ‰§è¡Œå›æ»šï¼šåˆ é™¤è¿™ä¸ªç›¸å†Œä¹‹å‰å·²ç»ä¸Šä¼ æˆåŠŸçš„å›¾ç‰‡
                                            if album_uploaded_paths:
                                                await asyncio.to_thread(
                                                    delete_from_supabase,
                                                    supabase, BUCKET_NAME, album_uploaded_paths
                                                )
                                            break
                                finally:
                                    if path and os.path.exists(path):
                                        try: os.remove(path)
                                        except: pass
                            
                            # å³ä½¿ä¸­æ–­ï¼Œä¹Ÿè¦ç»§ç»­æ£€æŸ¥æ–‡æœ¬æ›´æ–°
                            if m.text and len(m.text) > len(final_text):
                                final_text = m.text
                    
                    # åˆ†æ”¯ B: å•åª’ä½“ (Photo/Video)
                    elif message.media:
                        media_type = "photo" if message.photo else "video"
                        path = None
                        try:
                            path = await message.download_media(file=temp_dir)
                            if path:
                                url, _ = await asyncio.to_thread(
                                    upload_to_supabase_with_retry, 
                                    supabase, BUCKET_NAME, path, brand_folder
                                )
                                
                                if url: 
                                    media_urls.append(url)
                                else:
                                    error_msg = f"Supabase Upload Failed (Msg ID: {message.id})"
                                    logger.error(error_msg)
                                    await send_alert(error_msg, level="Upload_Error")
                                    is_payload_valid = False
                        finally:
                            if path and os.path.exists(path):
                                try: os.remove(path)
                                except: pass
                    
                    # åˆ†æ”¯ C: çº¯æ–‡æœ¬
                    else:
                        media_type = "text"

                    # æ„å»º Payload
                    if is_payload_valid:
                        payload = {
                            "source_channel": channel,
                            "brand": brand_folder,
                            "content": final_text,
                            "media_urls": media_urls, 
                            "media_type": media_type,
                            "message_id": final_msg_id,
                            "date": message.date.astimezone(manila_tz).isoformat()
                        }
                        payloads.append(payload)
                        logger.info(f"âœ… Prepared payload: {final_msg_id} ({media_type})")
                    else:
                        logger.warning(f"âš ï¸ Skipping Payload ID {final_msg_id} due to upload failure.")

            except Exception as e:
                err_msg = f"âŒ Error scraping channel {channel}: {e}"
                logger.error(err_msg)
                await send_alert(err_msg, level="Channel_Scrape_Error")
                continue
    
    # æ¨é€ n8n (ä¸²è¡Œæ¨¡å¼ - ä¿æŒç¨³å¥)
    if payloads:
        logger.info(f"ğŸš€ Pushing {len(payloads)} items to n8n...")
        headers = {'Authorization': N8N_AUTH_TOKEN} if N8N_AUTH_TOKEN else {}
        success_count = 0
        fail_count = 0

        async with httpx.AsyncClient(timeout=5.0) as http_client:
            for p in payloads:
                try:
                    r = await http_client.post(N8N_WEBHOOK_URL, json=p, headers=headers)
                    if r.status_code == 200:
                        logger.info(f"âœ… Sent ID {p['message_id']} to n8n")
                        success_count += 1
                    else:
                        logger.warning(f"âš ï¸ Webhook Failed {r.status_code} for ID {p['message_id']}")
                        fail_count += 1
                    await asyncio.sleep(1) 
                except Exception as e:
                    logger.error(f"âš ï¸ Webhook Connection Error: {e}")
                    fail_count += 1
        
        summary_msg = f"ğŸ“Š Job Summary: Scraped {len(payloads)}, Sent {success_count}, Failed {fail_count}."
        logger.info(summary_msg)
        
        if fail_count > 0:
             await send_alert(f"âš ï¸ Some items failed to push to n8n. {fail_count} failures.", level="Webhook_Warning")

    else:
        logger.info("ğŸ’¤ No new content found (or all skipped).")

    try:
        await client.disconnect()
    except: pass
    
    logger.info(f"ğŸ‘‹ Job Complete. Duration: {time.time() - start_time:.2f}s")

# å…¨å±€å¼‚å¸¸æ•è· (é—è¨€æœºåˆ¶)
if __name__ == '__main__':
    try:
        asyncio.run(main_logic())
    except Exception as e:
        # ç«‹å³æ‰“å°æ—¥å¿—ï¼Œç¡®ä¿åœ¨æ§åˆ¶å°å¯è§
        error_msg = f"ğŸ”¥ CRITICAL SCRIPT CRASH: {str(e)}\n\n{traceback.format_exc()}"
        logger.critical(error_msg)
        
        # å°è¯•å‘é€é—è¨€åˆ° n8n (åŒæ­¥é˜»å¡ç­‰å¾…)
        try:
            print("ğŸš¨ Attempting to send death rattle to n8n...", file=sys.stderr)
            asyncio.run(send_alert(error_msg, level="CRITICAL_CRASH"))
            print("âœ… Death rattle sent.", file=sys.stderr)
        except Exception as alert_error:
            # å³ä½¿æŠ¥è­¦å¤±è´¥ï¼Œä¹Ÿè¦æ‰“å°åˆ°æ§åˆ¶å°ï¼Œä»¥ä¾¿æŸ¥é˜… Railway æ—¥å¿—
            print(f"âŒ Failed to send crash alert: {alert_error}", file=sys.stderr)

        # æš´åŠ›é€€å‡º (é˜²æ­¢ Telegram çº¿ç¨‹å¡æ­» Railway)
        print("ğŸ’€ Executing os._exit(1) to kill zombie threads...", file=sys.stderr)
        os._exit(1)
